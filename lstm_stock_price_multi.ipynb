{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "stock_price_multi.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "RlDMI7BA_87_"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Change this flag to False to not plot anything\n",
        "PLOT = True\n",
        "     \n",
        "# Imports dataset\n",
        "df = pd.read_csv(\"spx_data.csv\")\n",
        "\n",
        "# Gets rid of time\n",
        "data = df.drop(\"Time\", 1)\n",
        "\n",
        "# Creates a list of closing prices as our features\n",
        "closing_price = data['SPX'].to_numpy().reshape(-1,1)\n",
        "\n",
        "if PLOT:\n",
        "  # Shows price action as well as some important data\n",
        "  fig,ax1 = plt.subplots()\n",
        "\n",
        "  ax1.plot(data['SPX'])\n",
        "  ax2 = ax1.twinx()\n",
        "  ax2.plot(data['VIX'],c='r')\n",
        "  ax2.plot(data['VOLSPD']/100000000,c='orange')\n",
        "  plt.title(\"S&P 500 10 min tick\")\n",
        "\n",
        "  plt.show()\n",
        "\n",
        "  # Shows correlation heat map\n",
        "  plt.figure(figsize=(10,8))\n",
        "  corr = data.corr()\n",
        "  sns.heatmap(corr, center=0)\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_mhAGfw344Xc"
      },
      "source": [
        "## Data pre-processing, Package import, Define critical function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wL7CQzbOzpMt"
      },
      "source": [
        "# Initial Scaling of data\n",
        "pd.options.mode.chained_assignment = None  # default='warn'\n",
        "train_data = data\n",
        "train_data['VIX'] = 1/85 * train_data['VIX']# Highest ever recorded VIX value\n",
        "train_data['ADSPD'] = 1/505 * train_data['ADSPD']# Highest number possible for $ADSPD\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM, Conv1D, MaxPooling1D, AveragePooling1D, Flatten, RepeatVector, TimeDistributed\n",
        "\n",
        "\n",
        "# Creates time series dataset to pass into Conv_LSTM NN\n",
        "# n_prev: how many previous values to include\n",
        "# n_fut: how many outputs to include (future data)\n",
        "def create_time_series(x_data, y_data, n_prev, n_fut=1):\n",
        "  x,y = [],[]\n",
        "  for i in range(n_prev, x_data.shape[0]-n_fut):\n",
        "    x.append(x_data[i-n_prev:i])\n",
        "    y.append(y_data[i:i+n_fut])\n",
        "\n",
        "  return np.array(x),np.array(y)\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yPWwgND3DQJe"
      },
      "source": [
        "# Phase 1: MLP model declaration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xcf4J-Wa4L5o"
      },
      "source": [
        "# Creates model and data process for Phase 1\n",
        "def phase1_mlp():\n",
        "\n",
        "  model = Sequential()\n",
        "  model.add(Dense(32,activation=\"relu\", input_dim=5))\n",
        "  model.add(Dense(32,activation=\"relu\"))\n",
        "  model.add(Dense(32,activation=\"tanh\"))\n",
        "  model.add(Dense(1,activation=\"sigmoid\"))\n",
        "  model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "  model.summary()\n",
        "\n",
        "  # epochs, batch_size=32\n",
        "  return model"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tHeTvuZOD5CQ"
      },
      "source": [
        "# Execute 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4pdrfhwrEMqB"
      },
      "source": [
        "model = phase1_mlp()\n",
        "train = train_data.drop([\"TVOLSP\",\"Return\",\"Return5h\",\"Return1h\", \"Return30min\"],1)\n",
        "train_x = train.iloc[:,:5]\n",
        "train_y = train.iloc[:,5:]\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "x_scaled = scaler.fit_transform(train_x)[:6916]\n",
        "y = train_y[:6916]\n",
        "\n",
        "\n",
        "assert x_scaled.shape[0] == y.shape[0]\n",
        "\n",
        "x_train, x_test = x_scaled[:5500], x_scaled[5500:]\n",
        "y_train, y_test = y.iloc[:5500,0], y.iloc[5500:,0]\n",
        "\n",
        "model.fit(x_train,y_train,epochs=50,batch_size=32,verbose=1,validation_data=(x_test,y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G0PR-UnwDWZw"
      },
      "source": [
        "# Phase 1.5: Conv 1D RNN model declaration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5db_Pxb7G9q"
      },
      "source": [
        "# Creates Conv1D and RNN model\n",
        "def phase1_5rnn():\n",
        "  conv_model = Sequential()\n",
        "  conv_model.add(Conv1D(128,2,input_shape=(300,5),activation='relu'))\n",
        "  conv_model.add(AveragePooling1D(2,1))\n",
        "  conv_model.add(Conv1D(64,2,activation='relu'))\n",
        "  conv_model.add(AveragePooling1D(2,1))\n",
        "  conv_model.add(LSTM(64))\n",
        "  conv_model.add(Dense(1,activation=\"sigmoid\"))\n",
        "  conv_model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "  conv_model.summary()\n",
        "\n",
        "  return conv_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ufMr57U-D8GA"
      },
      "source": [
        "# Execute 1.5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pKMnKX_JE1ST"
      },
      "source": [
        "train = train_data.drop([\"TVOLSP\",\"Return\",\"Return5h\",\"Return1h\", \"Return30min\"],1)\n",
        "train_x = train.iloc[:,:5]\n",
        "train_y = train.iloc[:,5:]\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "x_scaled = scaler.fit_transform(train_x)[:6916]\n",
        "y = train_y[:6916]\n",
        "y_data = y.to_numpy()\n",
        "\n",
        "x_train, x_test = x_scaled[:5500], x_scaled[5500:]\n",
        "y_train, y_test = y_data[:5500], y_data[5500:]\n",
        "\n",
        "\n",
        "x_train,y_train = create_time_series(x_train, y_train,300)\n",
        "x_test,y_test = create_time_series(x_test,y_test,300)\n",
        "\n",
        "y_train = y_train.reshape(-1,3)\n",
        "y_test = y_test.reshape(-1,3)\n",
        "\n",
        "x_train.shape, y_train.shape\n",
        "conv_model = phase1_5rnn()\n",
        "conv_model.fit(x_train,y_train[:,0],verbose=1,epochs=50,validation_data=(x_test,y_test[:,0]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "coMaEeaNDcVO"
      },
      "source": [
        "# Phase 2: LSTM model declaration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vus5nyR1owuy"
      },
      "source": [
        "# Creates LSTM model for regression\n",
        "def phase2_lstm():\n",
        "  n_prev, n_features, n_fut = 500, 5, 100\n",
        "  model = Sequential()\n",
        "  model.add(LSTM(100, activation='relu', input_shape=(n_prev, n_features)))\n",
        "  model.add(RepeatVector(n_fut))\n",
        "  model.add(LSTM(100, activation='relu', return_sequences=True))\n",
        "  model.add(TimeDistributed(Dense(50, activation='relu')))\n",
        "  model.add(TimeDistributed(Dense(1)))\n",
        "  model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "\n",
        "  model.summary()\n",
        "\n",
        "  return model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UHE7cabtECRU"
      },
      "source": [
        "# Execute 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LUqg117OF2XD"
      },
      "source": [
        "train = train_data.drop([\"TVOLSP\",\"Return\",\"Return5h\",\"Return1h\", \"Return30min\",\"Trend5h\",\"Trend1h\", \"Trend30min\"],1)\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "scaled_data = scaler.fit_transform(train)\n",
        "y=train['SPX'].to_numpy().reshape(-1,1)\n",
        "scaleY = MinMaxScaler()\n",
        "scaleY.fit_transform(y)\n",
        "\n",
        "n_prev, n_features, n_fut = 500, 5, 100\n",
        "epochs, batch_size = 1, 256\n",
        "\n",
        "train_x, train_y = create_time_series(scaled_data, scaled_data[:,0], n_prev, n_fut)\n",
        "# fit network\n",
        "model = phase2_lstm()\n",
        "model.fit(train_x, train_y, epochs=epochs, batch_size=batch_size, verbose=1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SqUfBUfaw-hm"
      },
      "source": [
        "# Plots 3x3 demo plots of projected vs ground truth\n",
        "test_x, test_y = train_x[6000:], train_y[6000:]\n",
        "\n",
        "y_hat = scaleY.inverse_transform(model.predict(test_x[0].reshape(1,n_prev,-1))[0])\n",
        "scaleY.inverse_transform(train_y[0].reshape(-1,1))\n",
        "\n",
        "plt.figure(figsize=(10,8))\n",
        "\n",
        "x_orig = scaler.inverse_transform(train_x[0])[:,0]\n",
        "\n",
        "offset=1000\n",
        "for i in range(9):\n",
        "  plt.subplot(3,3,i+1)\n",
        "  i = i * n_prev\n",
        "  y_pred = scaleY.inverse_transform(model.predict(train_x[i+offset].reshape(1,n_prev,-1))[0])\n",
        "  plt.plot(np.arange(i,i+n_prev+20),np.array(train_data['SPX'])[i+offset:i+n_prev+20+offset], 'c--')\n",
        "  plt.plot(np.arange(i+n_prev,i+n_prev+20),y_pred[:20],'r')\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IHL7BAA_DigY"
      },
      "source": [
        "# Phase 2.5: Conv2D+LSTM model declaration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NdJTt75b3kEf"
      },
      "source": [
        "def phase2_5convlstm():\n",
        "\n",
        "  model = Sequential()\n",
        "  model.add(Conv1D(32,3,activation='relu',input_shape=(n_timesteps, n_features)))\n",
        "  # model.add(LSTM(200, activation='relu', return_sequences=True))\n",
        "  model.add(Flatten())\n",
        "  model.add(RepeatVector(n_outputs))\n",
        "  model.add(LSTM(50, activation='relu', return_sequences=True))\n",
        "  model.add(TimeDistributed(Dense(100, activation='relu')))\n",
        "  model.add(TimeDistributed(Dense(1)))\n",
        "  model.compile(loss='mse', optimizer='adam')\n",
        "\n",
        "  model.summary()\n",
        "\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "860bfws3EEv_"
      },
      "source": [
        "# Execute 2.5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-OEnRTnIJ3sJ"
      },
      "source": [
        "phase2_5convlstm()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}